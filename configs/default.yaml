model_name: gpt2
dataset_path: data/sample_corpus.txt
output_dir: output/gpt2_finetuned

training_args:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 1
  learning_rate: 5e-5
  weight_decay: 0.01
  save_steps: 500
  logging_steps: 50
  save_total_limit: 2
  fp16: True
  push_to_hub: False

gen_max_length: 100
gen_num_return_sequences: 3